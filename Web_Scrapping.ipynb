{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3904e640-d97b-4a66-9dd3-d2c178898243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Page 1 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 2 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 3 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 4 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 5 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 6 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 7 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 8 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 9 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 10 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 11 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 12 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 13 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 14 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 15 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 16 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 17 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 18 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 19 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 20 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 21 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 22 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 23 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 24 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 25 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 26 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 27 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 28 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 29 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 30 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 31 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 32 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 33 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 34 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 35 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 36 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 37 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 38 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 39 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 40 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 41 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 42 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 43 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 44 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 45 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 46 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 47 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 48 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 49 Total length of the books are 20\n",
      "\n",
      "ðŸ“˜ Page 50 Total length of the books are 20\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "item = []\n",
    "for i in range(1,51):\n",
    "    url = f\"https://books.toscrape.com/catalogue/page-{i}.html\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code==200:\n",
    "        soup = BeautifulSoup(response.text,'lxml')\n",
    "        books = soup.find_all('article',class_='product_pod')\n",
    "        print(f\"\\nðŸ“˜ Page {i} Total length of the books are {len(books)}\")\n",
    "        for book in books:\n",
    "            title = book.h3.a['title']\n",
    "            price= book.find('p',class_='price_color').text.split('Â£')[1]\n",
    "            stock = book.find('p' ,class_=\"instock availability\").text.strip()\n",
    "            rating = book.find('p', class_='star-rating')['class'][1]\n",
    "            link = book.h3.a['href']\n",
    "            new = urljoin(url,link)\n",
    "            item.append([title,price,stock,rating,new])\n",
    "        df = pd.DataFrame((item),columns=['Title','Price($)','Avaliblity','Rating','link'])\n",
    "        df.to_csv('Scrap_books.csv')\n",
    "    else:\n",
    "        print(\"You Don't Have the Acess to Scrap this Site\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d5434-5137-4d19-8053-8dd82df10121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
